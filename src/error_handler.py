#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•ç³»ç»Ÿ
"""

import os
import sys
import traceback
import logging
import functools
import numpy as np
from typing import Any, Callable, Optional, Union, Type
from datetime import datetime


class ErrorHandler:
    """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self, log_file: Optional[str] = None, log_level: str = "INFO"):
        """
        åˆå§‹åŒ–é”™è¯¯å¤„ç†å™¨
        
        Args:
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            log_level: æ—¥å¿—çº§åˆ«
        """
        self.log_file = log_file or f"./logs/error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        self.log_level = getattr(logging, log_level.upper(), logging.INFO)
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(os.path.dirname(self.log_file), exist_ok=True)
        
        # é…ç½®æ—¥å¿—
        self._setup_logging()
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        # åˆ›å»ºlogger
        self.logger = logging.getLogger('BMW_BERT')
        self.logger.setLevel(self.log_level)
        
        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(self.log_level)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(self.log_level)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ å¤„ç†å™¨
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def log_error(self, message: str, exception: Optional[Exception] = None) -> None:
        """
        è®°å½•é”™è¯¯
        
        Args:
            message: é”™è¯¯æ¶ˆæ¯
            exception: å¼‚å¸¸å¯¹è±¡
        """
        if exception:
            self.logger.error(f"{message}: {str(exception)}")
            self.logger.debug(f"å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
        else:
            self.logger.error(message)
    
    def log_warning(self, message: str) -> None:
        """
        è®°å½•è­¦å‘Š
        
        Args:
            message: è­¦å‘Šæ¶ˆæ¯
        """
        self.logger.warning(message)
    
    def log_info(self, message: str) -> None:
        """
        è®°å½•ä¿¡æ¯
        
        Args:
            message: ä¿¡æ¯æ¶ˆæ¯
        """
        self.logger.info(message)
    
    def log_debug(self, message: str) -> None:
        """
        è®°å½•è°ƒè¯•ä¿¡æ¯
        
        Args:
            message: è°ƒè¯•æ¶ˆæ¯
        """
        self.logger.debug(message)
    
    def handle_exception(self, func: Callable) -> Callable:
        """
        å¼‚å¸¸å¤„ç†è£…é¥°å™¨
        
        Args:
            func: è¦è£…é¥°çš„å‡½æ•°
            
        Returns:
            è£…é¥°åçš„å‡½æ•°
        """
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                self.log_error(f"å‡½æ•° {func.__name__} æ‰§è¡Œå¤±è´¥", e)
                raise
        return wrapper
    
    def handle_oom(self, func: Callable) -> Callable:
        """
        OOMé”™è¯¯å¤„ç†è£…é¥°å™¨
        
        Args:
            func: è¦è£…é¥°çš„å‡½æ•°
            
        Returns:
            è£…é¥°åçš„å‡½æ•°
        """
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    self.log_warning(f"æ£€æµ‹åˆ°OOMé”™è¯¯ï¼Œå°è¯•æ¸…ç†å†…å­˜: {e}")
                    self._clear_memory()
                    # å°è¯•é™ä½æ‰¹æ¬¡å¤§å°é‡è¯•
                    if 'batch_size' in kwargs:
                        original_batch_size = kwargs['batch_size']
                        new_batch_size = max(1, original_batch_size // 2)
                        self.log_info(f"é™ä½æ‰¹æ¬¡å¤§å°é‡è¯•: {original_batch_size} -> {new_batch_size}")
                        kwargs['batch_size'] = new_batch_size
                        try:
                            return func(*args, **kwargs)
                        except Exception as retry_e:
                            self.log_error(f"é™ä½æ‰¹æ¬¡å¤§å°é‡è¯•å¤±è´¥", retry_e)
                            raise
                    else:
                        raise
                else:
                    raise
        return wrapper
    
    def _clear_memory(self) -> None:
        """æ¸…ç†å†…å­˜"""
        try:
            import gc
            import torch
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                self.log_info("GPUå†…å­˜å·²æ¸…ç†")
        except Exception as e:
            self.log_warning(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")
    
    def retry(self, max_retries: int = 3, delay: float = 1.0, 
              exceptions: tuple = (Exception,)) -> Callable:
        """
        é‡è¯•è£…é¥°å™¨
        
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            exceptions: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹
            
        Returns:
            è£…é¥°å™¨
        """
        def decorator(func: Callable) -> Callable:
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                last_exception = None
                for attempt in range(max_retries + 1):
                    try:
                        return func(*args, **kwargs)
                    except exceptions as e:
                        last_exception = e
                        if attempt < max_retries:
                            self.log_warning(f"å‡½æ•° {func.__name__} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                            self.log_info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                            import time
                            time.sleep(delay)
                        else:
                            self.log_error(f"å‡½æ•° {func.__name__} åœ¨ {max_retries + 1} æ¬¡å°è¯•åä»ç„¶å¤±è´¥", e)
                            raise
                raise last_exception
            return wrapper
        return decorator
    
    def validate_file_exists(self, file_path: str, description: str = "æ–‡ä»¶") -> bool:
        """
        éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            description: æ–‡ä»¶æè¿°
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        """
        if not os.path.exists(file_path):
            self.log_error(f"{description}ä¸å­˜åœ¨: {file_path}")
            return False
        return True
    
    def validate_dir_exists(self, dir_path: str, description: str = "ç›®å½•") -> bool:
        """
        éªŒè¯ç›®å½•æ˜¯å¦å­˜åœ¨
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            description: ç›®å½•æè¿°
            
        Returns:
            bool: ç›®å½•æ˜¯å¦å­˜åœ¨
        """
        if not os.path.exists(dir_path):
            self.log_error(f"{description}ä¸å­˜åœ¨: {dir_path}")
            return False
        if not os.path.isdir(dir_path):
            self.log_error(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {dir_path}")
            return False
        return True
    
    def validate_model_files(self, model_dir: str) -> bool:
        """
        éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
        
        Args:
            model_dir: æ¨¡å‹ç›®å½•
            
        Returns:
            bool: æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
        """
        required_files = ["config.json"]
        optional_files = ["tokenizer.json", "vocab.txt", "pytorch_model.bin"]
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        for file_name in required_files:
            file_path = os.path.join(model_dir, file_name)
            if not self.validate_file_exists(file_path, f"å¿…éœ€æ¨¡å‹æ–‡ä»¶ {file_name}"):
                return False
        
        # æ£€æŸ¥å¯é€‰æ–‡ä»¶ï¼ˆè‡³å°‘éœ€è¦ä¸€ä¸ªï¼‰
        tokenizer_found = False
        for file_name in optional_files:
            file_path = os.path.join(model_dir, file_name)
            if os.path.exists(file_path):
                tokenizer_found = True
                break
        
        if not tokenizer_found:
            self.log_error(f"æ¨¡å‹ç›®å½•ç¼ºå°‘åˆ†è¯å™¨æ–‡ä»¶: {model_dir}")
            return False
        
        self.log_info(f"æ¨¡å‹æ–‡ä»¶éªŒè¯é€šè¿‡: {model_dir}")
        return True
    
    def get_log_file(self) -> str:
        """è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
        return self.log_file
    
    def log_metrics(self, metrics: dict, category: str = "general") -> None:
        """
        è®°å½•è¯„ä¼°æŒ‡æ ‡
        
        Args:
            metrics: æŒ‡æ ‡å­—å…¸
            category: æŒ‡æ ‡ç±»åˆ«ï¼ˆå¦‚ 'performance', 'quality', 'error_analysis'ï¼‰
        """
        self.log_info(f"=== {category.upper()} æŒ‡æ ‡ ===")
        
        # æŒ‰ç±»åˆ«ç»„ç»‡æŒ‡æ ‡
        if category == "performance":
            self.log_info(f"  å¹³å‡å»¶è¿Ÿ: {metrics.get('avg_latency', 0):.4f}ç§’")
            self.log_info(f"  TP99å»¶è¿Ÿ: {metrics.get('tp99_latency', 0):.4f}ç§’")
            self.log_info(f"  TPS: {metrics.get('tps', 0):.2f}")
            self.log_info(f"  æ€»æ—¶é—´: {metrics.get('total_time', 0):.4f}ç§’")
            self.log_info(f"  æ ·æœ¬æ•°: {metrics.get('num_samples', 0)}")
        
        elif category == "quality":
            # åŸºç¡€æŒ‡æ ‡
            self.log_info("  ğŸ” åŸºç¡€æŒ‡æ ‡:")
            for k in ["accuracy", "f1_weighted", "f1_macro"]:
                if k in metrics:
                    self.log_info(f"    {k}: {metrics[k]:.4f}")
            
            # Hit@KæŒ‡æ ‡
            self.log_info("  ğŸ¯ Hit@KæŒ‡æ ‡:")
            for k in ["hit@1", "hit@3", "hit@5", "hit@10"]:
                if k in metrics and not np.isnan(metrics[k]):
                    self.log_info(f"    {k}: {metrics[k]:.4f}")
            
            # æ’åºè´¨é‡æŒ‡æ ‡
            self.log_info("  ğŸ“Š æ’åºè´¨é‡æŒ‡æ ‡:")
            for k in ["mrr", "ndcg@3", "ndcg@5", "ndcg@10"]:
                if k in metrics and not np.isnan(metrics[k]):
                    self.log_info(f"    {k}: {metrics[k]:.4f}")
            
            # è¦†ç›–ç‡æŒ‡æ ‡
            self.log_info("  ğŸŒ è¦†ç›–ç‡æŒ‡æ ‡:")
            for k in ["coverage@3", "coverage@5", "coverage@10"]:
                if k in metrics and not np.isnan(metrics[k]):
                    self.log_info(f"    {k}: {metrics[k]:.4f}")
        
        elif category == "confidence":
            self.log_info(f"  å¹³å‡ç½®ä¿¡åº¦: {metrics.get('avg_confidence', 0):.4f}")
            self.log_info(f"  æœ€ä½ç½®ä¿¡åº¦: {metrics.get('min_confidence', 0):.4f}")
            self.log_info(f"  æœ€é«˜ç½®ä¿¡åº¦: {metrics.get('max_confidence', 0):.4f}")
            
            # ç½®ä¿¡åº¦åˆ†å¸ƒ
            self.log_info("  ç½®ä¿¡åº¦åˆ†å¸ƒ:")
            for k, v in metrics.items():
                if k.startswith("confidence_") and isinstance(v, dict):
                    threshold = k.replace("confidence_", "")
                    self.log_info(f"    {threshold}+: {v['count']} ({v['percentage']:.1f}%)")
        
        elif category == "error_analysis":
            self.log_info("  é”™è¯¯ç±»å‹åˆ†æ:")
            for error_type, info in metrics.items():
                if isinstance(info, dict):
                    self.log_info(f"    {error_type}: {info['count']} ({info['percentage']:.1f}%)")
        
        elif category == "distribution":
            self.log_info("  é¢„æµ‹åˆ†å¸ƒ:")
            for item_name, info in metrics.items():
                if isinstance(info, dict):
                    self.log_info(f"    {item_name}: {info['count']} ({info['percentage']:.1f}%)")
        
        else:
            # é€šç”¨æŒ‡æ ‡è®°å½•
            for k, v in metrics.items():
                if isinstance(v, float):
                    self.log_info(f"  {k}: {v:.4f}")
                elif isinstance(v, dict):
                    self.log_info(f"  {k}: {v}")
                else:
                    self.log_info(f"  {k}: {v}")
    
    def log_experiment_summary(self, experiment_info: dict) -> None:
        """
        è®°å½•å®éªŒæ‘˜è¦
        
        Args:
            experiment_info: å®éªŒä¿¡æ¯å­—å…¸
        """
        self.log_info("=" * 50)
        self.log_info("å®éªŒæ‘˜è¦")
        self.log_info("=" * 50)
        
        # åŸºæœ¬ä¿¡æ¯
        self.log_info(f"å®éªŒæ—¶é—´: {experiment_info.get('timestamp', 'Unknown')}")
        self.log_info(f"æ¨¡å‹ç±»å‹: {experiment_info.get('model_type', 'Unknown')}")
        self.log_info(f"æ¨¡å‹è·¯å¾„: {experiment_info.get('model_path', 'Unknown')}")
        
        # æ•°æ®ä¿¡æ¯
        if 'data_info' in experiment_info:
            data_info = experiment_info['data_info']
            self.log_info(f"è®­ç»ƒæ ·æœ¬æ•°: {data_info.get('train_samples', 0)}")
            self.log_info(f"è¯„ä¼°æ ·æœ¬æ•°: {data_info.get('eval_samples', 0)}")
            self.log_info(f"æµ‹è¯•æ ·æœ¬æ•°: {data_info.get('test_samples', 0)}")
            self.log_info(f"ç±»åˆ«æ•°: {data_info.get('num_classes', 0)}")
        
        # å…³é”®æŒ‡æ ‡
        if 'key_metrics' in experiment_info:
            key_metrics = experiment_info['key_metrics']
            self.log_info("å…³é”®æŒ‡æ ‡:")
            for metric_name, value in key_metrics.items():
                if isinstance(value, float):
                    self.log_info(f"  {metric_name}: {value:.4f}")
                else:
                    self.log_info(f"  {metric_name}: {value}")
        
        # è¾“å‡ºæ–‡ä»¶
        if 'output_files' in experiment_info:
            self.log_info("è¾“å‡ºæ–‡ä»¶:")
            for file_type, file_path in experiment_info['output_files'].items():
                self.log_info(f"  {file_type}: {file_path}")
        
        self.log_info("=" * 50)


# å…¨å±€é”™è¯¯å¤„ç†å™¨å®ä¾‹
_error_handler = None


def get_error_handler(log_file: Optional[str] = None, 
                   log_level: str = "INFO") -> ErrorHandler:
    """è·å–å…¨å±€é”™è¯¯å¤„ç†å™¨å®ä¾‹"""
    global _error_handler
    if _error_handler is None:
        _error_handler = ErrorHandler(log_file, log_level)
    return _error_handler


def reset_error_handler() -> None:
    """é‡ç½®å…¨å±€é”™è¯¯å¤„ç†å™¨"""
    global _error_handler
    _error_handler = None


def log_error(message: str, exception: Optional[Exception] = None) -> None:
    """è®°å½•é”™è¯¯çš„ä¾¿æ·å‡½æ•°"""
    get_error_handler().log_error(message, exception)


def log_warning(message: str) -> None:
    """è®°å½•è­¦å‘Šçš„ä¾¿æ·å‡½æ•°"""
    get_error_handler().log_warning(message)


def log_info(message: str) -> None:
    """è®°å½•ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°"""
    get_error_handler().log_info(message)


def log_debug(message: str) -> None:
    """è®°å½•è°ƒè¯•ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°"""
    get_error_handler().log_debug(message)


def handle_exception(func: Callable) -> Callable:
    """å¼‚å¸¸å¤„ç†è£…é¥°å™¨çš„ä¾¿æ·å‡½æ•°"""
    return get_error_handler().handle_exception(func)


def handle_oom(func: Callable) -> Callable:
    """OOMé”™è¯¯å¤„ç†è£…é¥°å™¨çš„ä¾¿æ·å‡½æ•°"""
    return get_error_handler().handle_oom(func)


def retry(max_retries: int = 3, delay: float = 1.0,
          exceptions: tuple = (Exception,)) -> Callable:
    """é‡è¯•è£…é¥°å™¨çš„ä¾¿æ·å‡½æ•°"""
    return get_error_handler().retry(max_retries, delay, exceptions)


def log_metrics(metrics: dict, category: str = "general") -> None:
    """è®°å½•è¯„ä¼°æŒ‡æ ‡çš„ä¾¿æ·å‡½æ•°"""
    get_error_handler().log_metrics(metrics, category)


def log_experiment_summary(experiment_info: dict) -> None:
    """è®°å½•å®éªŒæ‘˜è¦çš„ä¾¿æ·å‡½æ•°"""
    get_error_handler().log_experiment_summary(experiment_info)