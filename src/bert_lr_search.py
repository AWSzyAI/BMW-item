#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
BERTå­¦ä¹ ç‡è‡ªåŠ¨åŒ–æœç´¢è„šæœ¬
è‡ªåŠ¨æµ‹è¯•ä¸åŒå­¦ä¹ ç‡å’Œè°ƒåº¦å™¨ç»„åˆï¼Œæ‰¾åˆ°æœ€ä½³é…ç½®
"""

import os
import json
import argparse
import subprocess
import time
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import numpy as np

def run_single_experiment(lr, scheduler_type, warmup_ratio, patience, data_dir, other_args):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_name = f"lr_{lr}_sched_{scheduler_type}_warmup_{warmup_ratio}_{timestamp}"
    
    # æ„å»ºè¾“å‡ºç›®å½• - æ‰€æœ‰æ¨¡å‹æ–‡ä»¶éƒ½ä¿å­˜åœ¨checkpointç›®å½•ä¸‹
    exp_outdir = f"./output/lr_search/{exp_name}"
    exp_checkpoint_dir = f"./checkpoints/lr_search/{exp_name}"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(exp_outdir, exist_ok=True)
    os.makedirs(exp_checkpoint_dir, exist_ok=True)
    
    # ç¡®ä¿çˆ¶ç›®å½•ä¹Ÿå­˜åœ¨
    os.makedirs(os.path.dirname(exp_outdir), exist_ok=True)
    os.makedirs(os.path.dirname(exp_checkpoint_dir), exist_ok=True)
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        "python", "src/train_bert.py",
        "--learning-rate", str(lr),
        "--lr-scheduler-type", scheduler_type,
        "--warmup-ratio", str(warmup_ratio),
        "--early-stopping-patience", str(patience),
        "--outdir", data_dir,  # ä½¿ç”¨åŸå§‹æ•°æ®ç›®å½•è€Œä¸æ˜¯å®éªŒè¾“å‡ºç›®å½•
        "--experiment-outdir", exp_outdir,  # å®éªŒè¾“å‡ºç›®å½•ç”¨äºä¿å­˜ç»“æœ
        "--checkpoint-dir", exp_checkpoint_dir,  # checkpointç›®å½•ç”¨äºä¿å­˜æ¨¡å‹
        "--outmodel", f"{exp_name}.joblib",
        "--num-train-epochs", "10",  # é™åˆ¶epochæ•°ä»¥åŠ å¿«æœç´¢
    ] + other_args
    
    print(f"\nğŸš€ å¼€å§‹å®éªŒ: {exp_name}")
    print(f"ğŸ“Š å­¦ä¹ ç‡: {lr}, è°ƒåº¦å™¨: {scheduler_type}, é¢„çƒ­æ¯”ä¾‹: {warmup_ratio}")
    print(f"ğŸ”§ å‘½ä»¤: {' '.join(cmd)}")
    
    # è¿è¡Œå®éªŒ
    start_time = time.time()
    print(f"â±ï¸  å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S', time.localtime(start_time))}")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨å®æ—¶è¾“å‡ºè€Œä¸æ˜¯ capture_outputï¼Œä»¥ä¾¿çœ‹åˆ°è®­ç»ƒè¿›åº¦
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                               text=True, universal_newlines=True)
        
        # å®æ—¶è¾“å‡ºæ—¥å¿—
        last_log_time = time.time()
        training_started = False
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                # ç›´æ¥è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼Œè®©è®­ç»ƒè„šæœ¬çš„è¯¦ç»†æ—¥å¿—æ˜¾ç¤º
                print(output.strip())
                
                # æ£€æµ‹è®­ç»ƒæ˜¯å¦å¼€å§‹
                if "ğŸš€ å¼€å§‹è®­ç»ƒ..." in output:
                    training_started = True
                
                # å¦‚æœè®­ç»ƒå·²ç»å¼€å§‹ï¼Œæ¯10ç§’è¾“å‡ºä¸€æ¬¡å®éªŒè¿›åº¦ä¿¡æ¯
                if training_started:
                    current_time = time.time()
                    if current_time - last_log_time > 10:
                        elapsed = current_time - start_time
                        print(f"\nâ³ å®éªŒè¿›è¡Œä¸­... å·²è€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ")
                        last_log_time = current_time
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        return_code = process.poll()
        end_time = time.time()
        elapsed = end_time - start_time
        
        if return_code == 0:
            print("=" * 60)
            print(f"âœ… å®éªŒå®Œæˆï¼Œæ€»è€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ")
            
            # è§£æç»“æœ
            metrics_file = os.path.join(exp_outdir, "metrics_eval.csv")
            if os.path.exists(metrics_file):
                metrics_df = pd.read_csv(metrics_file)
                best_hit3 = metrics_df['hit@3'].iloc[0] if 'hit@3' in metrics_df.columns else float('nan')
                best_accuracy = metrics_df['accuracy'].iloc[0] if 'accuracy' in metrics_df.columns else float('nan')
                best_f1_macro = metrics_df['f1_macro'].iloc[0] if 'f1_macro' in metrics_df.columns else float('nan')
            else:
                # å¦‚æœmetrics_eval.csvä¸å­˜åœ¨ï¼Œå°è¯•ä»è®­ç»ƒæ—¥å¿—ä¸­è§£æè¯„ä¼°æŒ‡æ ‡
                print(f"âš ï¸  æœªæ‰¾åˆ°è¯„ä¼°æŒ‡æ ‡æ–‡ä»¶ {metrics_file}ï¼Œå°è¯•ä»è®­ç»ƒæ—¥å¿—è§£æ...")
                
                # å°è¯•ä»checkpointç›®å½•ä¸­æŸ¥æ‰¾æœ€ä½³æ¨¡å‹çš„è¯„ä¼°ç»“æœ
                checkpoint_bert_dir = os.path.join(exp_checkpoint_dir, "bert")
                if os.path.exists(checkpoint_bert_dir):
                    # æŸ¥æ‰¾trainer_state.jsonæ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«è®­ç»ƒå†å²
                    trainer_state_file = os.path.join(checkpoint_bert_dir, "trainer_state.json")
                    if os.path.exists(trainer_state_file):
                        try:
                            with open(trainer_state_file, 'r') as f:
                                trainer_state = json.load(f)
                            
                            # ä»log_historyä¸­æ‰¾åˆ°æœ€ä½³è¯„ä¼°ç»“æœ
                            best_hit3 = best_accuracy = best_f1_macro = float('nan')
                            if 'log_history' in trainer_state:
                                for log_entry in trainer_state['log_history']:
                                    if 'eval_hit@3' in log_entry:
                                        best_hit3 = max(best_hit3, log_entry['eval_hit@3'])
                                    if 'eval_accuracy' in log_entry:
                                        best_accuracy = max(best_accuracy, log_entry['eval_accuracy'])
                                    if 'eval_f1_macro' in log_entry:
                                        best_f1_macro = max(best_f1_macro, log_entry['eval_f1_macro'])
                            
                            print(f"âœ“ ä»è®­ç»ƒæ—¥å¿—è§£æå¾—åˆ°: hit@3={best_hit3:.4f}, accuracy={best_accuracy:.4f}, f1_macro={best_f1_macro:.4f}")
                        except Exception as e:
                            print(f"âš ï¸  è§£æè®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")
                            best_hit3 = best_accuracy = best_f1_macro = float('nan')
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒçŠ¶æ€æ–‡ä»¶ {trainer_state_file}")
                        best_hit3 = best_accuracy = best_f1_macro = float('nan')
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½• {checkpoint_bert_dir}")
                    best_hit3 = best_accuracy = best_f1_macro = float('nan')
            
            return {
                'exp_name': exp_name,
                'learning_rate': lr,
                'scheduler_type': scheduler_type,
                'warmup_ratio': warmup_ratio,
                'patience': patience,
                'best_hit3': best_hit3,
                'best_accuracy': best_accuracy,
                'best_f1_macro': best_f1_macro,
                'training_time': elapsed,
                'status': 'success',
                'outdir': exp_outdir,
                'checkpoint_dir': exp_checkpoint_dir
            }
        else:
            print("=" * 60)
            print(f"âŒ å®éªŒå¤±è´¥ï¼Œè€—æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ")
            return {
                'exp_name': exp_name,
                'learning_rate': lr,
                'scheduler_type': scheduler_type,
                'warmup_ratio': warmup_ratio,
                'patience': patience,
                'best_hit3': float('nan'),
                'best_accuracy': float('nan'),
                'best_f1_macro': float('nan'),
                'training_time': elapsed,
                'status': 'failed',
                'error': f"è¿›ç¨‹è¿”å›ç : {return_code}",
                'outdir': exp_outdir,
                'checkpoint_dir': exp_checkpoint_dir
            }
    
    except subprocess.TimeoutExpired:
        print("=" * 60)
        print(f"â° å®éªŒè¶…æ—¶ï¼ˆ1å°æ—¶ï¼‰")
        return {
            'exp_name': exp_name,
            'learning_rate': lr,
            'scheduler_type': scheduler_type,
            'warmup_ratio': warmup_ratio,
            'patience': patience,
            'best_hit3': float('nan'),
            'best_accuracy': float('nan'),
            'best_f1_macro': float('nan'),
            'training_time': 3600,
            'status': 'timeout',
            'outdir': exp_outdir,
            'checkpoint_dir': exp_checkpoint_dir
        }

def visualize_results(results_df, output_dir):
    """å¯è§†åŒ–æœç´¢ç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. å­¦ä¹ ç‡ vs hit@3 çƒ­åŠ›å›¾
    plt.figure(figsize=(12, 8))
    
    # åˆ›å»ºé€è§†è¡¨
    pivot_hit3 = results_df.pivot_table(
        values='best_hit3', 
        index='learning_rate', 
        columns='scheduler_type', 
        aggfunc='max'
    )
    
    sns.heatmap(pivot_hit3, annot=True, fmt='.4f', cmap='YlOrRd', 
                xticklabels=True, yticklabels=True)
    plt.title('Learning Rate vs Scheduler Type (Best Hit@3)')
    plt.xlabel('Scheduler Type')
    plt.ylabel('Learning Rate')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'lr_scheduler_heatmap.png'), dpi=300)
    plt.close()
    
    # 2. å­¦ä¹ ç‡ vs hit@3 æŠ˜çº¿å›¾
    plt.figure(figsize=(12, 8))
    
    for scheduler in results_df['scheduler_type'].unique():
        scheduler_data = results_df[results_df['scheduler_type'] == scheduler]
        plt.plot(scheduler_data['learning_rate'], scheduler_data['best_hit3'], 
                marker='o', label=scheduler, linewidth=2, markersize=6)
    
    plt.xscale('log')
    plt.xlabel('Learning Rate (log scale)')
    plt.ylabel('Best Hit@3')
    plt.title('Learning Rate vs Best Hit@3 by Scheduler Type')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'lr_hit3_curves.png'), dpi=300)
    plt.close()
    
    # 3. é¢„çƒ­æ¯”ä¾‹å½±å“åˆ†æ
    if 'warmup_ratio' in results_df.columns:
        plt.figure(figsize=(10, 6))
        warmup_pivot = results_df.groupby('warmup_ratio')['best_hit3'].mean().reset_index()
        plt.bar(warmup_pivot['warmup_ratio'], warmup_pivot['best_hit3'])
        plt.xlabel('Warmup Ratio')
        plt.ylabel('Average Best Hit@3')
        plt.title('Warmup Ratio Impact on Performance')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'warmup_impact.png'), dpi=300)
        plt.close()
    
    # 4. è®­ç»ƒæ—¶é—´åˆ†æ
    plt.figure(figsize=(10, 6))
    plt.scatter(results_df['best_hit3'], results_df['training_time'], alpha=0.6)
    plt.xlabel('Best Hit@3')
    plt.ylabel('Training Time (seconds)')
    plt.title('Performance vs Training Time')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_vs_time.png'), dpi=300)
    plt.close()

def main(args):
    print("ğŸ” BERTå­¦ä¹ ç‡è‡ªåŠ¨åŒ–æœç´¢å¼€å§‹")
    
    # å®šä¹‰æœç´¢ç©ºé—´
    learning_rates = args.learning_rates
    scheduler_types = args.scheduler_types
    warmup_ratios = args.warmup_ratios
    
    print(f"ğŸ“Š æœç´¢ç©ºé—´:")
    print(f"   å­¦ä¹ ç‡: {learning_rates}")
    print(f"   è°ƒåº¦å™¨: {scheduler_types}")
    print(f"   é¢„çƒ­æ¯”ä¾‹: {warmup_ratios}")
    
    # ç”Ÿæˆå®éªŒç»„åˆ
    experiments = []
    for lr in learning_rates:
        for scheduler in scheduler_types:
            for warmup in warmup_ratios:
                experiments.append((lr, scheduler, warmup))
    
    print(f"ğŸ§ª æ€»å…± {len(experiments)} ä¸ªå®éªŒç»„åˆ")
    
    # å…¶ä»–å‚æ•°
    other_args = []
    if args.bert_model:
        other_args.extend(["--bert-model", args.bert_model])
    if args.init_hf_dir:
        other_args.extend(["--init-hf-dir", args.init_hf_dir])
    if args.allow_online:
        other_args.append("--allow-online")
    if args.train_batch_size:
        other_args.extend(["--train-batch-size", str(args.train_batch_size)])
    if args.eval_batch_size:
        other_args.extend(["--eval-batch-size", str(args.eval_batch_size)])
    if args.max_length:
        other_args.extend(["--max-length", str(args.max_length)])
    if args.fp16:
        other_args.append("--fp16")
    
    # è¿è¡Œå®éªŒ
    results = []
    total_start = time.time()
    experiment_times = []  # è®°å½•æ¯ä¸ªå®éªŒçš„è€—æ—¶ï¼Œç”¨äºä¼°ç®—å‰©ä½™æ—¶é—´
    
    for i, (lr, scheduler, warmup) in enumerate(experiments, 1):
        print(f"\nğŸ“ è¿›åº¦: {i}/{len(experiments)} ({i/len(experiments)*100:.1f}%)")
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        if experiment_times:
            avg_time = sum(experiment_times) / len(experiment_times)
            remaining_experiments = len(experiments) - i
            eta_minutes = avg_time * remaining_experiments / 60
            eta_hours = eta_minutes / 60
            if eta_hours >= 1:
                print(f"â±ï¸  é¢„è®¡å‰©ä½™æ—¶é—´: {eta_hours:.1f}å°æ—¶")
            else:
                print(f"â±ï¸  é¢„è®¡å‰©ä½™æ—¶é—´: {eta_minutes:.1f}åˆ†é’Ÿ")
        
        result = run_single_experiment(lr, scheduler, warmup, args.patience, args.data_dir, other_args)
        results.append(result)
        
        # è®°å½•å®éªŒè€—æ—¶
        if result['training_time']:
            experiment_times.append(result['training_time'])
        
        # ä¿å­˜ä¸­é—´ç»“æœ
        results_df = pd.DataFrame(results)
        results_df.to_csv("./lr_search_results.csv", index=False)
        
        # ç»Ÿè®¡çŠ¶æ€
        successful_count = sum(1 for r in results if r['status'] == 'success')
        failed_count = sum(1 for r in results if r['status'] == 'failed')
        timeout_count = sum(1 for r in results if r['status'] == 'timeout')
        
        print(f"ğŸ“Š çŠ¶æ€ç»Ÿè®¡: æˆåŠŸ {successful_count} | å¤±è´¥ {failed_count} | è¶…æ—¶ {timeout_count}")
        
        # å¦‚æœæ˜¯æœ€ä½³ç»“æœï¼Œæ‰“å°ä¿¡æ¯
        successful_results = [r for r in results if r['status'] == 'success']
        if successful_results:
            best_result = max(successful_results, key=lambda x: x['best_hit3'])
            print(f"ğŸ† å½“å‰æœ€ä½³: {best_result['exp_name']} (hit@3={best_result['best_hit3']:.4f})")
    
    total_time = time.time() - total_start
    total_hours = total_time / 3600
    if total_hours >= 1:
        print(f"\nğŸ‰ æœç´¢å®Œæˆï¼æ€»è€—æ—¶: {total_hours:.1f}å°æ—¶")
    else:
        print(f"\nğŸ‰ æœç´¢å®Œæˆï¼æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    
    # åˆ†æç»“æœ
    results_df = pd.DataFrame(results)
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    results_df.to_csv("./lr_search_results.csv", index=False)
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: lr_search_results.csv")
    
    # æˆåŠŸå®éªŒåˆ†æ
    successful_results = results_df[results_df['status'] == 'success']
    if len(successful_results) > 0:
        print(f"\nâœ… æˆåŠŸå®éªŒ: {len(successful_results)}/{len(results)}")
        
        # æœ€ä½³ç»“æœ
        best_result = successful_results.loc[successful_results['best_hit3'].idxmax()]
        print(f"\nğŸ† æœ€ä½³é…ç½®:")
        print(f"   å®éªŒåç§°: {best_result['exp_name']}")
        print(f"   å­¦ä¹ ç‡: {best_result['learning_rate']}")
        print(f"   è°ƒåº¦å™¨: {best_result['scheduler_type']}")
        print(f"   é¢„çƒ­æ¯”ä¾‹: {best_result['warmup_ratio']}")
        print(f"   æœ€ä½³hit@3: {best_result['best_hit3']:.4f}")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.4f}")
        print(f"   è®­ç»ƒæ—¶é—´: {best_result['training_time']:.1f}ç§’")
        print(f"   æ¨¡å‹è·¯å¾„: {best_result['checkpoint_dir']}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        print(f"\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–...")
        visualize_results(successful_results, "./lr_search_visualizations")
        print(f"ğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: lr_search_visualizations/")
        
        # ä¿å­˜æœ€ä½³é…ç½®
        best_config = {
            'learning_rate': best_result['learning_rate'],
            'lr_scheduler_type': best_result['scheduler_type'],
            'warmup_ratio': best_result['warmup_ratio'],
            'early_stopping_patience': args.patience,
            'best_hit3': best_result['best_hit3'],
            'best_accuracy': best_result['best_accuracy'],
            'model_path': best_result['checkpoint_dir']
        }
        
        with open("./best_lr_config.json", "w", encoding="utf-8") as f:
            json.dump(best_config, f, indent=2, ensure_ascii=False)
        print(f"âš™ï¸ æœ€ä½³é…ç½®å·²ä¿å­˜åˆ°: best_lr_config.json")
    
    else:
        print(f"\nâŒ æ‰€æœ‰å®éªŒéƒ½å¤±è´¥äº†")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="BERTå­¦ä¹ ç‡è‡ªåŠ¨åŒ–æœç´¢")
    
    # æœç´¢ç©ºé—´å‚æ•°
    parser.add_argument("--learning-rates", type=float, nargs='+',
                       default=[1e-5, 3e-5, 5e-5, 1e-4, 3e-4],
                       help="å­¦ä¹ ç‡æœç´¢åˆ—è¡¨")
    parser.add_argument("--scheduler-types", type=str, nargs='+',
                       choices=["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"],
                       default=["cosine", "linear", "polynomial"],
                       help="è°ƒåº¦å™¨ç±»å‹æœç´¢åˆ—è¡¨")
    parser.add_argument("--warmup-ratios", type=float, nargs='+',
                       default=[0.0, 0.05, 0.1, 0.2],
                       help="é¢„çƒ­æ¯”ä¾‹æœç´¢åˆ—è¡¨")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--data-dir", type=str, default="./output/2025_up_to_month_7", help="è®­ç»ƒæ•°æ®ç›®å½•")
    parser.add_argument("--patience", type=int, default=3, help="æ—©åœè€å¿ƒå€¼")
    parser.add_argument("--bert-model", type=str, default="./models", help="BERTæ¨¡å‹è·¯å¾„")
    parser.add_argument("--init-hf-dir", type=str, help="æœ¬åœ°HFæ¨¡å‹ç›®å½•")
    parser.add_argument("--allow-online", action="store_true", help="å…è®¸åœ¨çº¿ä¸‹è½½")
    parser.add_argument("--train-batch-size", type=int, default=16, help="è®­ç»ƒæ‰¹æ¬¡å¤§å°")
    parser.add_argument("--eval-batch-size", type=int, default=32, help="è¯„ä¼°æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--max-length", type=int, default=256, help="æœ€å¤§åºåˆ—é•¿åº¦")
    parser.add_argument("--fp16", action="store_true", help="å¯ç”¨æ··åˆç²¾åº¦")
    
    args = parser.parse_args()
    main(args)